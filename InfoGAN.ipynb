{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import random \n",
    "import torchvision.transforms as tfs\n",
    "from torchvision.utils import save_image\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as dset\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import itertools\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import PIL.ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pottery data and augmented methods as described in official example InfoGAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  5409\n"
     ]
    }
   ],
   "source": [
    "manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "transformations = [\n",
    "                   tfs.Resize((112, 112)),\n",
    "                   tfs.Grayscale(1),\n",
    "                   tfs.Lambda(lambda x: PIL.ImageOps.invert(x)),\n",
    "                   tfs.ToTensor()]\n",
    "\n",
    "dataset = dset.ImageFolder('data/png_clasificados/',\n",
    "                                     transform=tfs.Compose(transformations))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter definitions for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "def to_categorical(y, num_columns=11):\n",
    "    \"\"\"Returns one-hot encoded Variable\"\"\"\n",
    "    y_cat = np.zeros((y.shape[0], num_columns))\n",
    "    y_cat[range(y.shape[0]), y] = 1.\n",
    "\n",
    "    return Variable(FloatTensor(y_cat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create $G(x)$ and $D(x)$ with weights initialization, define criterion and optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.infogenerator import Generator\n",
    "from models.infodiscriminator import Discriminator\n",
    "\n",
    "# Loss functions\n",
    "adversarial_loss = torch.nn.MSELoss()\n",
    "categorical_loss = torch.nn.CrossEntropyLoss()\n",
    "continuous_loss = torch.nn.MSELoss()\n",
    "\n",
    "# Loss weights\n",
    "lambda_cat = 1\n",
    "lambda_con = 0.1\n",
    "\n",
    "# Initialize generator and discriminator\n",
    "netG = Generator()\n",
    "netD = Discriminator()\n",
    "\n",
    "\n",
    "netG.cuda()\n",
    "netD.cuda()\n",
    "adversarial_loss.cuda()\n",
    "categorical_loss.cuda()\n",
    "continuous_loss.cuda()\n",
    "\n",
    "# Initialize weights\n",
    "netG.apply(weights_init_normal)\n",
    "netD.apply(weights_init_normal)\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_info = torch.optim.Adam(itertools.chain(netG.parameters(), netD.parameters()),\n",
    "                                    lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor\n",
    "#FloatTensor = torch.FloatTensor\n",
    "#LongTensor = torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "static_z = Variable(FloatTensor(np.zeros((11**2, 62))))\n",
    "static_label = to_categorical(np.array([num for _ in range(11) for num in range(11)]),\n",
    "                                num_columns=11)\n",
    "\n",
    "static_code = Variable(FloatTensor(np.zeros((11**2, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image(n_row, batches_done):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Static sample\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row**2, 62))))\n",
    "    static_sample = netG(z, static_label, static_code)\n",
    "    save_image(static_sample.data, 'out/static_%d.png' % batches_done, nrow=n_row, normalize=True)\n",
    "\n",
    "    # Get varied c1 and c2\n",
    "    zeros = np.zeros((n_row**2, 1))\n",
    "    c_varied = np.repeat(np.linspace(-1, 1, n_row)[:, np.newaxis], n_row, 0)\n",
    "    c1 = Variable(FloatTensor(np.concatenate((c_varied, zeros), -1)))\n",
    "    c2 = Variable(FloatTensor(np.concatenate((zeros, c_varied), -1)))\n",
    "    sample1 = netG(static_z, static_label, c1)\n",
    "    sample2 = netG(static_z, static_label, c2)\n",
    "    save_image(sample1.data, 'out/c1_%d.png' % batches_done, nrow=n_row, normalize=True)\n",
    "    save_image(sample2.data, 'out/c2_%d.png' % batches_done, nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train $G(x)$ , $D(x)$ and calculate information loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/400] [Batch 0/21] [D loss: 0.493480] [G loss: 0.986736] [info loss: 2.620036]\n",
      "[Epoch 0/400] [Batch 1/21] [D loss: 0.491779] [G loss: 0.983794] [info loss: 2.573261]\n",
      "[Epoch 0/400] [Batch 2/21] [D loss: 0.489931] [G loss: 0.980199] [info loss: 2.617831]\n",
      "[Epoch 0/400] [Batch 3/21] [D loss: 0.487247] [G loss: 0.974698] [info loss: 2.595105]\n",
      "[Epoch 0/400] [Batch 4/21] [D loss: 0.483560] [G loss: 0.967247] [info loss: 2.593553]\n",
      "[Epoch 0/400] [Batch 5/21] [D loss: 0.478536] [G loss: 0.957331] [info loss: 2.581253]\n",
      "[Epoch 0/400] [Batch 6/21] [D loss: 0.472338] [G loss: 0.944221] [info loss: 2.582580]\n",
      "[Epoch 0/400] [Batch 7/21] [D loss: 0.464474] [G loss: 0.928286] [info loss: 2.593290]\n",
      "[Epoch 0/400] [Batch 8/21] [D loss: 0.453671] [G loss: 0.906881] [info loss: 2.629110]\n",
      "[Epoch 0/400] [Batch 9/21] [D loss: 0.442241] [G loss: 0.881457] [info loss: 2.624499]\n",
      "[Epoch 0/400] [Batch 10/21] [D loss: 0.426958] [G loss: 0.849875] [info loss: 2.590659]\n",
      "[Epoch 0/400] [Batch 11/21] [D loss: 0.411201] [G loss: 0.811828] [info loss: 2.556008]\n",
      "[Epoch 0/400] [Batch 12/21] [D loss: 0.391702] [G loss: 0.769194] [info loss: 2.560309]\n",
      "[Epoch 0/400] [Batch 13/21] [D loss: 0.370933] [G loss: 0.717704] [info loss: 2.591804]\n",
      "[Epoch 0/400] [Batch 14/21] [D loss: 0.348932] [G loss: 0.662167] [info loss: 2.553065]\n",
      "[Epoch 0/400] [Batch 15/21] [D loss: 0.325510] [G loss: 0.598029] [info loss: 2.565053]\n",
      "[Epoch 0/400] [Batch 16/21] [D loss: 0.306355] [G loss: 0.529049] [info loss: 2.551450]\n",
      "[Epoch 0/400] [Batch 17/21] [D loss: 0.288169] [G loss: 0.450504] [info loss: 2.537550]\n",
      "[Epoch 0/400] [Batch 18/21] [D loss: 0.273007] [G loss: 0.376872] [info loss: 2.562807]\n",
      "[Epoch 0/400] [Batch 19/21] [D loss: 0.271303] [G loss: 0.309792] [info loss: 2.550430]\n",
      "[Epoch 0/400] [Batch 20/21] [D loss: 0.268903] [G loss: 0.219602] [info loss: 2.566171]\n",
      "[Epoch 1/400] [Batch 0/21] [D loss: 0.267109] [G loss: 0.210326] [info loss: 2.505515]\n",
      "[Epoch 1/400] [Batch 1/21] [D loss: 0.269346] [G loss: 0.194328] [info loss: 2.521285]\n",
      "[Epoch 1/400] [Batch 2/21] [D loss: 0.268132] [G loss: 0.188646] [info loss: 2.536879]\n",
      "[Epoch 1/400] [Batch 3/21] [D loss: 0.276597] [G loss: 0.192435] [info loss: 2.493275]\n",
      "[Epoch 1/400] [Batch 4/21] [D loss: 0.253863] [G loss: 0.212562] [info loss: 2.484793]\n",
      "[Epoch 1/400] [Batch 5/21] [D loss: 0.257385] [G loss: 0.220360] [info loss: 2.505749]\n",
      "[Epoch 1/400] [Batch 6/21] [D loss: 0.259180] [G loss: 0.228747] [info loss: 2.511938]\n",
      "[Epoch 1/400] [Batch 7/21] [D loss: 0.256150] [G loss: 0.236680] [info loss: 2.487733]\n",
      "[Epoch 1/400] [Batch 8/21] [D loss: 0.253862] [G loss: 0.256008] [info loss: 2.505233]\n",
      "[Epoch 1/400] [Batch 9/21] [D loss: 0.253403] [G loss: 0.268945] [info loss: 2.497179]\n",
      "[Epoch 1/400] [Batch 10/21] [D loss: 0.241593] [G loss: 0.306091] [info loss: 2.497977]\n",
      "[Epoch 1/400] [Batch 11/21] [D loss: 0.238079] [G loss: 0.297047] [info loss: 2.492500]\n",
      "[Epoch 1/400] [Batch 12/21] [D loss: 0.241619] [G loss: 0.295999] [info loss: 2.464476]\n",
      "[Epoch 1/400] [Batch 13/21] [D loss: 0.250689] [G loss: 0.289344] [info loss: 2.481665]\n",
      "[Epoch 1/400] [Batch 14/21] [D loss: 0.258941] [G loss: 0.315811] [info loss: 2.488959]\n",
      "[Epoch 1/400] [Batch 15/21] [D loss: 0.262554] [G loss: 0.270748] [info loss: 2.475704]\n",
      "[Epoch 1/400] [Batch 16/21] [D loss: 0.273370] [G loss: 0.262942] [info loss: 2.452258]\n",
      "[Epoch 1/400] [Batch 17/21] [D loss: 0.273550] [G loss: 0.265638] [info loss: 2.471508]\n",
      "[Epoch 1/400] [Batch 18/21] [D loss: 0.261879] [G loss: 0.283572] [info loss: 2.471151]\n",
      "[Epoch 1/400] [Batch 19/21] [D loss: 0.253185] [G loss: 0.291880] [info loss: 2.447168]\n",
      "[Epoch 1/400] [Batch 20/21] [D loss: 0.215122] [G loss: 0.332778] [info loss: 2.386110]\n",
      "[Epoch 2/400] [Batch 0/21] [D loss: 0.239843] [G loss: 0.282953] [info loss: 2.446650]\n",
      "[Epoch 2/400] [Batch 1/21] [D loss: 0.241879] [G loss: 0.293160] [info loss: 2.446751]\n",
      "[Epoch 2/400] [Batch 2/21] [D loss: 0.230828] [G loss: 0.270388] [info loss: 2.422937]\n",
      "[Epoch 2/400] [Batch 3/21] [D loss: 0.215163] [G loss: 0.329455] [info loss: 2.426500]\n",
      "[Epoch 2/400] [Batch 4/21] [D loss: 0.197883] [G loss: 0.379854] [info loss: 2.421706]\n",
      "[Epoch 2/400] [Batch 5/21] [D loss: 0.192888] [G loss: 0.407137] [info loss: 2.411738]\n",
      "[Epoch 2/400] [Batch 6/21] [D loss: 0.158777] [G loss: 0.489802] [info loss: 2.406090]\n",
      "[Epoch 2/400] [Batch 7/21] [D loss: 0.155554] [G loss: 0.485761] [info loss: 2.404727]\n",
      "[Epoch 2/400] [Batch 8/21] [D loss: 0.155943] [G loss: 0.548182] [info loss: 2.400634]\n",
      "[Epoch 2/400] [Batch 9/21] [D loss: 0.147856] [G loss: 0.534582] [info loss: 2.389616]\n",
      "[Epoch 2/400] [Batch 10/21] [D loss: 0.148418] [G loss: 0.547794] [info loss: 2.376919]\n",
      "[Epoch 2/400] [Batch 11/21] [D loss: 0.130670] [G loss: 0.566384] [info loss: 2.369403]\n",
      "[Epoch 2/400] [Batch 12/21] [D loss: 0.153259] [G loss: 0.503982] [info loss: 2.364853]\n",
      "[Epoch 2/400] [Batch 13/21] [D loss: 0.153960] [G loss: 0.544916] [info loss: 2.358654]\n",
      "[Epoch 2/400] [Batch 14/21] [D loss: 0.144039] [G loss: 0.599571] [info loss: 2.343441]\n",
      "[Epoch 2/400] [Batch 15/21] [D loss: 0.187974] [G loss: 0.577284] [info loss: 2.322322]\n",
      "[Epoch 2/400] [Batch 16/21] [D loss: 0.158527] [G loss: 0.564532] [info loss: 2.320812]\n",
      "[Epoch 2/400] [Batch 17/21] [D loss: 0.175463] [G loss: 0.482542] [info loss: 2.291619]\n",
      "[Epoch 2/400] [Batch 18/21] [D loss: 0.154329] [G loss: 0.619230] [info loss: 2.233119]\n",
      "[Epoch 2/400] [Batch 19/21] [D loss: 0.150304] [G loss: 0.742568] [info loss: 2.223397]\n",
      "[Epoch 2/400] [Batch 20/21] [D loss: 0.059265] [G loss: 0.725882] [info loss: 2.407359]\n",
      "[Epoch 3/400] [Batch 0/21] [D loss: 0.187504] [G loss: 0.916537] [info loss: 2.187862]\n",
      "[Epoch 3/400] [Batch 1/21] [D loss: 0.192642] [G loss: 0.777261] [info loss: 2.181818]\n",
      "[Epoch 3/400] [Batch 2/21] [D loss: 0.098302] [G loss: 0.683726] [info loss: 2.158115]\n",
      "[Epoch 3/400] [Batch 3/21] [D loss: 0.105568] [G loss: 0.669601] [info loss: 2.086920]\n",
      "[Epoch 3/400] [Batch 4/21] [D loss: 0.130386] [G loss: 0.864519] [info loss: 2.063806]\n",
      "[Epoch 3/400] [Batch 5/21] [D loss: 0.105382] [G loss: 0.802400] [info loss: 1.993865]\n",
      "[Epoch 3/400] [Batch 6/21] [D loss: 0.101952] [G loss: 0.968833] [info loss: 1.996454]\n",
      "[Epoch 3/400] [Batch 7/21] [D loss: 0.085363] [G loss: 0.941828] [info loss: 1.941419]\n",
      "[Epoch 3/400] [Batch 8/21] [D loss: 0.163795] [G loss: 0.804545] [info loss: 1.842869]\n",
      "[Epoch 3/400] [Batch 9/21] [D loss: 0.080950] [G loss: 0.722827] [info loss: 1.748921]\n",
      "[Epoch 3/400] [Batch 10/21] [D loss: 0.116100] [G loss: 0.906999] [info loss: 1.746230]\n",
      "[Epoch 3/400] [Batch 11/21] [D loss: 0.124154] [G loss: 0.837948] [info loss: 1.761842]\n",
      "[Epoch 3/400] [Batch 12/21] [D loss: 0.117103] [G loss: 0.867922] [info loss: 1.705321]\n",
      "[Epoch 3/400] [Batch 13/21] [D loss: 0.099218] [G loss: 1.042134] [info loss: 1.692105]\n",
      "[Epoch 3/400] [Batch 14/21] [D loss: 0.103911] [G loss: 1.047873] [info loss: 1.704216]\n",
      "[Epoch 3/400] [Batch 15/21] [D loss: 0.084413] [G loss: 0.906639] [info loss: 1.636366]\n",
      "[Epoch 3/400] [Batch 16/21] [D loss: 0.094326] [G loss: 1.016629] [info loss: 1.620572]\n",
      "[Epoch 3/400] [Batch 17/21] [D loss: 0.103001] [G loss: 0.677201] [info loss: 1.603544]\n",
      "[Epoch 3/400] [Batch 18/21] [D loss: 0.119241] [G loss: 0.985377] [info loss: 1.638703]\n",
      "[Epoch 3/400] [Batch 19/21] [D loss: 0.078960] [G loss: 0.876382] [info loss: 1.654011]\n",
      "[Epoch 3/400] [Batch 20/21] [D loss: 0.070679] [G loss: 0.461452] [info loss: 1.689027]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(400):\n",
    "    for i, (imgs, labels) in enumerate(dataloader):\n",
    "\n",
    "        batch_size = imgs.shape[0]\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(FloatTensor(batch_size, 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(FloatTensor(batch_size, 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(FloatTensor))\n",
    "        labels = to_categorical(labels.numpy(), num_columns=11)\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizerG.zero_grad()\n",
    "\n",
    "        # Sample noise and labels as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, 62))))\n",
    "        label_input = to_categorical(np.random.randint(0, 11, batch_size), num_columns=11)\n",
    "        code_input = Variable(FloatTensor(np.random.uniform(-1, 1, (batch_size, 2))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        gen_imgs = netG(z, label_input, code_input)\n",
    "\n",
    "        # Loss measures generator's ability to fool the discriminator\n",
    "        validity, _, _ = netD(gen_imgs)\n",
    "        g_loss = adversarial_loss(validity, valid)\n",
    "\n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizerD.zero_grad()\n",
    "\n",
    "        # Loss for real images\n",
    "        real_pred, _, _ = netD(real_imgs)\n",
    "        d_real_loss = adversarial_loss(real_pred, valid)\n",
    "\n",
    "        # Loss for fake images\n",
    "        fake_pred, _, _ = netD(gen_imgs.detach())\n",
    "        d_fake_loss = adversarial_loss(fake_pred, fake)\n",
    "\n",
    "        # Total discriminator loss\n",
    "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
    "\n",
    "        d_loss.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        #------------------\n",
    "        # Information Loss\n",
    "        #------------------\n",
    "\n",
    "        optimizer_info.zero_grad()\n",
    "\n",
    "        # Sample labels\n",
    "        sampled_labels = np.random.randint(0, 11, batch_size)\n",
    "\n",
    "        # Ground truth labels\n",
    "        gt_labels = Variable(LongTensor(sampled_labels), requires_grad=False)\n",
    "\n",
    "\n",
    "        # Sample noise, labels and code as generator input\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (batch_size, 62))))\n",
    "        label_input = to_categorical(sampled_labels, num_columns=11)\n",
    "        code_input = Variable(FloatTensor(np.random.normal(-1, 1, (batch_size, 2))))\n",
    "\n",
    "        gen_imgs = netG(z, label_input, code_input)\n",
    "        _, pred_label, pred_code = netD(gen_imgs)\n",
    "\n",
    "        info_loss = lambda_cat * categorical_loss(pred_label, gt_labels) + \\\n",
    "                    lambda_con * continuous_loss(pred_code, code_input)\n",
    "\n",
    "        info_loss.backward()\n",
    "        optimizer_info.step()\n",
    "\n",
    "        #--------------\n",
    "        # Log Progress\n",
    "        #--------------\n",
    "\n",
    "        print (\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [info loss: %f]\" % (epoch, 400, i, len(dataloader),\n",
    "                                                            d_loss.item(), g_loss.item(), info_loss.item()))\n",
    "        batches_done = epoch * len(dataloader) + i\n",
    "        if batches_done % 100 == 0:\n",
    "            sample_image(n_row=11, batches_done=batches_done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funcs to get generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_image_class(n_row, batches_done=-1, class_n=7):\n",
    "    \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\"\n",
    "    # Sample noise\n",
    "    z = Variable(FloatTensor(np.random.normal(0, 1, (n_row**2, 100))))\n",
    "    # Get labels ranging from 0 to n_classes for n rows\n",
    "    labels = np.array([num for _ in range(n_row) for num in [class_n] * n_row])\n",
    "    print(labels)\n",
    "    labels = Variable(LongTensor(labels))\n",
    "    gen_imgs = netG(z, labels)\n",
    "    save_image(gen_imgs.data, 'out/class_%d_%d.png' % (batches_done, class_n) , nrow=n_row, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(100):\n",
    "        z = Variable(FloatTensor(np.random.normal(0, 1, (10**2, 62))))\n",
    "        fake = netG(z, static_label, static_code)\n",
    "        # save_image(static_sample.data, 'out/static_%d.png' % batches_done, nrow=n_row, normalize=True)\n",
    "        for i in range(100):\n",
    "            for class_ in range(10):\n",
    "                if class_ == 4:\n",
    "                    save_image(fake.detach()[i], 'output/fake_infogan_{}{}_class_{}.png'.format(j, i, class_),\n",
    "                              nrow=1, normalize=True)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_class(10, class_n=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
