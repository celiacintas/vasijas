{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import scipy.ndimage as nd\n",
    "import scipy.io as io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.measure as sk\n",
    "import utils\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as tfs\n",
    "from torch.utils import data\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_data = datasets.ImageFolder('data/png/',\n",
    "                                     transform=tfs.Compose([tfs.RandomChoice([tfs.ColorJitter()]),\n",
    "                                                           tfs.Resize((112, 112)),\n",
    "                                                           tfs.Grayscale(1)]))\n",
    "      \n",
    "data_loader = data.DataLoader(imagenet_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<PIL.Image.Image image mode=L size=112x112 at 0x7F44773CF320>, 0)\n",
      "(<PIL.Image.Image image mode=L size=112x112 at 0x7F447714F6A0>, 0)\n",
      "(<PIL.Image.Image image mode=L size=112x112 at 0x7F44773EF940>, 0)\n",
      "(<PIL.Image.Image image mode=L size=112x112 at 0x7F44773C36D8>, 0)\n",
      "(<PIL.Image.Image image mode=L size=112x112 at 0x7F448F990A90>, 0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(imagenet_data)):\n",
    "    sample = imagenet_data[i + 10]\n",
    "    print(sample)\n",
    "    #print(i, sample.shape)\n",
    "    ax = plt.subplot(1, 5, i + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(np.asarray(sample[0]))\n",
    "    ax.set_title('Sample {}'.format(i))\n",
    "    ax.axis('off')\n",
    "\n",
    "    if i == 4:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define generator & GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from generator import _G\n",
    "from discriminator import _D\n",
    "from gan import GAN\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Networks architecture -------------\n",
      "_G(\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=1024, out_features=100352, bias=True)\n",
      "    (4): BatchNorm1d(100352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (deconv): Sequential(\n",
      "    (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): ConvTranspose2d(64, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 103262401\n",
      "_D(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (4): LeakyReLU(negative_slope=0.2)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=100352, out_features=1024, bias=True)\n",
      "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (4): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 102897089\n",
      "-----------------------------------------------\n",
      "training start!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/celia/code/vasijas/gan.py:53: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  self.sample_z_ = Variable(torch.rand((self.batch_size, self.z_dim)).cuda(), volatile=True)\n",
      "/home/celia/code/vasijas/gan.py:145: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.train_hist['D_loss'].append(D_loss.data[0])\n",
      "/home/celia/code/vasijas/gan.py:156: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  self.train_hist['G_loss'].append(G_loss.data[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg one epoch time: 2.26, total 200 epochs time: 462.29\n",
      "Training finish!... save training results\n",
      " [*] Training finished!\n",
      " [*] Testing finished!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "gan = GAN(epochs=200, input_h_w=112)\n",
    "gan.train()\n",
    "print(\"Training finished!\")\n",
    "\n",
    "# visualize learned generator\n",
    "gan.visualize_results(gan.epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML('<img src=\"/tmp/.gif\">')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
