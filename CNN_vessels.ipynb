{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import scipy.ndimage as nd\n",
    "import scipy.io as io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.measure as sk\n",
    "from utils import utils\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms as tfs\n",
    "from torch.utils import data\n",
    "\n",
    "import torch\n",
    "import PIL.ImageOps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [tfs.RandomAffine(0., scale=(0.5, 1.), fillcolor=0),\n",
    "                   tfs.Resize((64, 64)),\n",
    "                   tfs.Grayscale(1),\n",
    "                   tfs.Lambda(lambda x: PIL.ImageOps.invert(x))]\n",
    "\n",
    "imagenet_data = datasets.ImageFolder('data/png_clasificados/',\n",
    "                                     transform=tfs.Compose(transformations))\n",
    "\n",
    "data_loader = data.DataLoader(imagenet_data, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(len(imagenet_data)):\n",
    "    sample = imagenet_data[i + 10]\n",
    "    #print(sample)\n",
    "    ax = plt.subplot(1, 5, i + 1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(np.asarray(sample[0]), cmap=plt.cm.gray_r)\n",
    "    ax.set_title('Sample {}'.format(i))\n",
    "    ax.axis('off')\n",
    "\n",
    "    if i == 4:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process type of vessels for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = utils.create_df_from_files(path='data/clases/')\n",
    "# destination = \"data/perfiles_CATA/png_clasificados/\"\n",
    "# path = \"data/perfiles_CATA/png\"\n",
    "# utils.create_folder_pytorch_format(df, destination, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_data = datasets.ImageFolder('data/png_clasificados/',\n",
    "                                     transform=tfs.Compose([tfs.RandomHorizontalFlip(p=0.7),\n",
    "                                                           tfs.RandomAffine(0, scale=(0.7, 1.), fillcolor=0),\n",
    "                                                           tfs.Resize((64, 64)),\n",
    "                                                           tfs.Grayscale(1),\n",
    "                                                           tfs.Lambda(lambda x: PIL.ImageOps.invert(x)),\n",
    "                                                           tfs.ToTensor(),\n",
    "                                                           tfs.Normalize((0.5,), (0.5,))]))\n",
    "\n",
    "#data_loader = data.DataLoader(imagenet_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1133, 227, 793, 113)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(imagenet_data.samples), round(1133*0.2), round(1133*0.7), round(1133*0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = utils.random_split(imagenet_data, [227, 113, 793])\n",
    "\n",
    "train_loader = data.DataLoader(splits[2], batch_size=32, shuffle=True)\n",
    "val_loader = data.DataLoader(splits[1], batch_size=32, shuffle=True)\n",
    "test_loader = data.DataLoader(splits[0], batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from models.classifier import _C\n",
    "import visdom\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import CategoricalAccuracy, Loss\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results - Epoch: 1  Avg accuracy: 0.29 Avg loss: 2.27\n",
      "Validation Results - Epoch: 1  Avg accuracy: 0.27 Avg loss: 2.28\n",
      "Training Results - Epoch: 2  Avg accuracy: 0.66 Avg loss: 2.07\n",
      "Validation Results - Epoch: 2  Avg accuracy: 0.61 Avg loss: 2.09\n",
      "Training Results - Epoch: 3  Avg accuracy: 0.71 Avg loss: 1.86\n",
      "Validation Results - Epoch: 3  Avg accuracy: 0.66 Avg loss: 1.89\n",
      "Training Results - Epoch: 4  Avg accuracy: 0.73 Avg loss: 1.79\n",
      "Validation Results - Epoch: 4  Avg accuracy: 0.70 Avg loss: 1.83\n",
      "Training Results - Epoch: 5  Avg accuracy: 0.73 Avg loss: 1.77\n",
      "Validation Results - Epoch: 5  Avg accuracy: 0.65 Avg loss: 1.82\n",
      "Training Results - Epoch: 6  Avg accuracy: 0.76 Avg loss: 1.75\n",
      "Validation Results - Epoch: 6  Avg accuracy: 0.72 Avg loss: 1.78\n",
      "Training Results - Epoch: 7  Avg accuracy: 0.78 Avg loss: 1.75\n",
      "Validation Results - Epoch: 7  Avg accuracy: 0.70 Avg loss: 1.78\n",
      "Training Results - Epoch: 8  Avg accuracy: 0.77 Avg loss: 1.74\n",
      "Validation Results - Epoch: 8  Avg accuracy: 0.70 Avg loss: 1.79\n",
      "Training Results - Epoch: 9  Avg accuracy: 0.81 Avg loss: 1.73\n",
      "Validation Results - Epoch: 9  Avg accuracy: 0.70 Avg loss: 1.78\n",
      "Training Results - Epoch: 10  Avg accuracy: 0.80 Avg loss: 1.71\n",
      "Validation Results - Epoch: 10  Avg accuracy: 0.75 Avg loss: 1.76\n",
      "Training Results - Epoch: 11  Avg accuracy: 0.80 Avg loss: 1.72\n",
      "Validation Results - Epoch: 11  Avg accuracy: 0.73 Avg loss: 1.77\n",
      "Training Results - Epoch: 12  Avg accuracy: 0.82 Avg loss: 1.69\n",
      "Validation Results - Epoch: 12  Avg accuracy: 0.71 Avg loss: 1.74\n",
      "Training Results - Epoch: 13  Avg accuracy: 0.82 Avg loss: 1.69\n",
      "Validation Results - Epoch: 13  Avg accuracy: 0.80 Avg loss: 1.72\n",
      "Training Results - Epoch: 14  Avg accuracy: 0.84 Avg loss: 1.69\n",
      "Validation Results - Epoch: 14  Avg accuracy: 0.78 Avg loss: 1.75\n",
      "Training Results - Epoch: 15  Avg accuracy: 0.83 Avg loss: 1.69\n",
      "Validation Results - Epoch: 15  Avg accuracy: 0.75 Avg loss: 1.74\n",
      "Training Results - Epoch: 16  Avg accuracy: 0.83 Avg loss: 1.67\n",
      "Validation Results - Epoch: 16  Avg accuracy: 0.80 Avg loss: 1.72\n",
      "Training Results - Epoch: 17  Avg accuracy: 0.85 Avg loss: 1.66\n",
      "Validation Results - Epoch: 17  Avg accuracy: 0.81 Avg loss: 1.70\n",
      "Training Results - Epoch: 18  Avg accuracy: 0.81 Avg loss: 1.71\n",
      "Validation Results - Epoch: 18  Avg accuracy: 0.73 Avg loss: 1.77\n",
      "Training Results - Epoch: 19  Avg accuracy: 0.82 Avg loss: 1.66\n",
      "Validation Results - Epoch: 19  Avg accuracy: 0.76 Avg loss: 1.73\n",
      "Training Results - Epoch: 20  Avg accuracy: 0.85 Avg loss: 1.70\n",
      "Validation Results - Epoch: 20  Avg accuracy: 0.75 Avg loss: 1.77\n",
      "Training Results - Epoch: 21  Avg accuracy: 0.84 Avg loss: 1.65\n",
      "Validation Results - Epoch: 21  Avg accuracy: 0.77 Avg loss: 1.73\n",
      "Training Results - Epoch: 22  Avg accuracy: 0.87 Avg loss: 1.65\n",
      "Validation Results - Epoch: 22  Avg accuracy: 0.83 Avg loss: 1.70\n",
      "Training Results - Epoch: 23  Avg accuracy: 0.87 Avg loss: 1.64\n",
      "Validation Results - Epoch: 23  Avg accuracy: 0.80 Avg loss: 1.71\n",
      "Training Results - Epoch: 24  Avg accuracy: 0.83 Avg loss: 1.65\n",
      "Validation Results - Epoch: 24  Avg accuracy: 0.77 Avg loss: 1.72\n",
      "Training Results - Epoch: 25  Avg accuracy: 0.87 Avg loss: 1.65\n",
      "Validation Results - Epoch: 25  Avg accuracy: 0.84 Avg loss: 1.72\n",
      "Training Results - Epoch: 26  Avg accuracy: 0.87 Avg loss: 1.63\n",
      "Validation Results - Epoch: 26  Avg accuracy: 0.83 Avg loss: 1.70\n",
      "Training Results - Epoch: 27  Avg accuracy: 0.89 Avg loss: 1.63\n",
      "Validation Results - Epoch: 27  Avg accuracy: 0.82 Avg loss: 1.69\n",
      "Training Results - Epoch: 28  Avg accuracy: 0.85 Avg loss: 1.64\n",
      "Validation Results - Epoch: 28  Avg accuracy: 0.77 Avg loss: 1.71\n",
      "Training Results - Epoch: 29  Avg accuracy: 0.85 Avg loss: 1.63\n",
      "Validation Results - Epoch: 29  Avg accuracy: 0.85 Avg loss: 1.69\n",
      "Training Results - Epoch: 30  Avg accuracy: 0.83 Avg loss: 1.68\n",
      "Validation Results - Epoch: 30  Avg accuracy: 0.77 Avg loss: 1.77\n",
      "Training Results - Epoch: 31  Avg accuracy: 0.90 Avg loss: 1.63\n",
      "Validation Results - Epoch: 31  Avg accuracy: 0.86 Avg loss: 1.70\n",
      "Training Results - Epoch: 32  Avg accuracy: 0.90 Avg loss: 1.63\n",
      "Validation Results - Epoch: 32  Avg accuracy: 0.86 Avg loss: 1.69\n",
      "Training Results - Epoch: 33  Avg accuracy: 0.89 Avg loss: 1.64\n",
      "Validation Results - Epoch: 33  Avg accuracy: 0.78 Avg loss: 1.69\n",
      "Training Results - Epoch: 34  Avg accuracy: 0.89 Avg loss: 1.62\n",
      "Validation Results - Epoch: 34  Avg accuracy: 0.81 Avg loss: 1.69\n",
      "Training Results - Epoch: 35  Avg accuracy: 0.87 Avg loss: 1.63\n",
      "Validation Results - Epoch: 35  Avg accuracy: 0.79 Avg loss: 1.69\n",
      "Training Results - Epoch: 36  Avg accuracy: 0.87 Avg loss: 1.63\n",
      "Validation Results - Epoch: 36  Avg accuracy: 0.81 Avg loss: 1.70\n",
      "Training Results - Epoch: 37  Avg accuracy: 0.90 Avg loss: 1.61\n",
      "Validation Results - Epoch: 37  Avg accuracy: 0.85 Avg loss: 1.68\n",
      "Training Results - Epoch: 38  Avg accuracy: 0.92 Avg loss: 1.61\n",
      "Validation Results - Epoch: 38  Avg accuracy: 0.83 Avg loss: 1.69\n",
      "Training Results - Epoch: 39  Avg accuracy: 0.91 Avg loss: 1.61\n",
      "Validation Results - Epoch: 39  Avg accuracy: 0.85 Avg loss: 1.68\n",
      "Training Results - Epoch: 40  Avg accuracy: 0.87 Avg loss: 1.62\n",
      "Validation Results - Epoch: 40  Avg accuracy: 0.79 Avg loss: 1.70\n",
      "Training Results - Epoch: 41  Avg accuracy: 0.90 Avg loss: 1.61\n",
      "Validation Results - Epoch: 41  Avg accuracy: 0.84 Avg loss: 1.70\n",
      "Training Results - Epoch: 42  Avg accuracy: 0.91 Avg loss: 1.61\n",
      "Validation Results - Epoch: 42  Avg accuracy: 0.85 Avg loss: 1.69\n",
      "Training Results - Epoch: 43  Avg accuracy: 0.86 Avg loss: 1.62\n",
      "Validation Results - Epoch: 43  Avg accuracy: 0.82 Avg loss: 1.69\n",
      "Training Results - Epoch: 44  Avg accuracy: 0.92 Avg loss: 1.61\n",
      "Validation Results - Epoch: 44  Avg accuracy: 0.84 Avg loss: 1.68\n",
      "Training Results - Epoch: 45  Avg accuracy: 0.92 Avg loss: 1.60\n",
      "Validation Results - Epoch: 45  Avg accuracy: 0.88 Avg loss: 1.66\n",
      "Training Results - Epoch: 46  Avg accuracy: 0.93 Avg loss: 1.60\n",
      "Validation Results - Epoch: 46  Avg accuracy: 0.88 Avg loss: 1.67\n",
      "Training Results - Epoch: 47  Avg accuracy: 0.88 Avg loss: 1.61\n",
      "Validation Results - Epoch: 47  Avg accuracy: 0.82 Avg loss: 1.67\n",
      "Training Results - Epoch: 48  Avg accuracy: 0.92 Avg loss: 1.60\n",
      "Validation Results - Epoch: 48  Avg accuracy: 0.84 Avg loss: 1.69\n",
      "Training Results - Epoch: 49  Avg accuracy: 0.91 Avg loss: 1.61\n",
      "Validation Results - Epoch: 49  Avg accuracy: 0.82 Avg loss: 1.68\n",
      "Training Results - Epoch: 50  Avg accuracy: 0.91 Avg loss: 1.60\n",
      "Validation Results - Epoch: 50  Avg accuracy: 0.85 Avg loss: 1.68\n",
      "Training Results - Epoch: 51  Avg accuracy: 0.88 Avg loss: 1.64\n",
      "Validation Results - Epoch: 51  Avg accuracy: 0.81 Avg loss: 1.71\n",
      "Training Results - Epoch: 52  Avg accuracy: 0.91 Avg loss: 1.60\n",
      "Validation Results - Epoch: 52  Avg accuracy: 0.86 Avg loss: 1.67\n",
      "Training Results - Epoch: 53  Avg accuracy: 0.92 Avg loss: 1.61\n",
      "Validation Results - Epoch: 53  Avg accuracy: 0.83 Avg loss: 1.70\n",
      "Training Results - Epoch: 54  Avg accuracy: 0.91 Avg loss: 1.60\n",
      "Validation Results - Epoch: 54  Avg accuracy: 0.82 Avg loss: 1.68\n",
      "Training Results - Epoch: 55  Avg accuracy: 0.91 Avg loss: 1.60\n",
      "Validation Results - Epoch: 55  Avg accuracy: 0.85 Avg loss: 1.69\n",
      "Training Results - Epoch: 56  Avg accuracy: 0.91 Avg loss: 1.60\n",
      "Validation Results - Epoch: 56  Avg accuracy: 0.84 Avg loss: 1.68\n",
      "Training Results - Epoch: 57  Avg accuracy: 0.91 Avg loss: 1.60\n",
      "Validation Results - Epoch: 57  Avg accuracy: 0.84 Avg loss: 1.67\n",
      "Training Results - Epoch: 58  Avg accuracy: 0.92 Avg loss: 1.60\n",
      "Validation Results - Epoch: 58  Avg accuracy: 0.85 Avg loss: 1.70\n",
      "Training Results - Epoch: 59  Avg accuracy: 0.92 Avg loss: 1.58\n",
      "Validation Results - Epoch: 59  Avg accuracy: 0.89 Avg loss: 1.65\n",
      "Training Results - Epoch: 60  Avg accuracy: 0.92 Avg loss: 1.60\n",
      "Validation Results - Epoch: 60  Avg accuracy: 0.86 Avg loss: 1.67\n",
      "Training Results - Epoch: 61  Avg accuracy: 0.94 Avg loss: 1.60\n",
      "Validation Results - Epoch: 61  Avg accuracy: 0.81 Avg loss: 1.68\n",
      "Training Results - Epoch: 62  Avg accuracy: 0.93 Avg loss: 1.59\n",
      "Validation Results - Epoch: 62  Avg accuracy: 0.88 Avg loss: 1.66\n",
      "Training Results - Epoch: 63  Avg accuracy: 0.93 Avg loss: 1.59\n",
      "Validation Results - Epoch: 63  Avg accuracy: 0.87 Avg loss: 1.67\n",
      "Training Results - Epoch: 64  Avg accuracy: 0.94 Avg loss: 1.58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Results - Epoch: 64  Avg accuracy: 0.82 Avg loss: 1.69\n",
      "Training Results - Epoch: 65  Avg accuracy: 0.91 Avg loss: 1.60\n",
      "Validation Results - Epoch: 65  Avg accuracy: 0.84 Avg loss: 1.68\n",
      "Training Results - Epoch: 66  Avg accuracy: 0.95 Avg loss: 1.59\n",
      "Validation Results - Epoch: 66  Avg accuracy: 0.87 Avg loss: 1.68\n",
      "Training Results - Epoch: 67  Avg accuracy: 0.89 Avg loss: 1.62\n",
      "Validation Results - Epoch: 67  Avg accuracy: 0.78 Avg loss: 1.70\n",
      "Training Results - Epoch: 68  Avg accuracy: 0.92 Avg loss: 1.59\n",
      "Validation Results - Epoch: 68  Avg accuracy: 0.86 Avg loss: 1.66\n",
      "Training Results - Epoch: 69  Avg accuracy: 0.93 Avg loss: 1.59\n",
      "Validation Results - Epoch: 69  Avg accuracy: 0.82 Avg loss: 1.70\n",
      "Training Results - Epoch: 70  Avg accuracy: 0.93 Avg loss: 1.59\n",
      "Validation Results - Epoch: 70  Avg accuracy: 0.86 Avg loss: 1.67\n",
      "Training Results - Epoch: 71  Avg accuracy: 0.91 Avg loss: 1.59\n",
      "Validation Results - Epoch: 71  Avg accuracy: 0.83 Avg loss: 1.67\n",
      "Training Results - Epoch: 72  Avg accuracy: 0.92 Avg loss: 1.59\n",
      "Validation Results - Epoch: 72  Avg accuracy: 0.88 Avg loss: 1.67\n",
      "Training Results - Epoch: 73  Avg accuracy: 0.93 Avg loss: 1.58\n",
      "Validation Results - Epoch: 73  Avg accuracy: 0.88 Avg loss: 1.66\n",
      "Training Results - Epoch: 74  Avg accuracy: 0.94 Avg loss: 1.59\n",
      "Validation Results - Epoch: 74  Avg accuracy: 0.86 Avg loss: 1.67\n",
      "Training Results - Epoch: 75  Avg accuracy: 0.94 Avg loss: 1.58\n",
      "Validation Results - Epoch: 75  Avg accuracy: 0.85 Avg loss: 1.67\n",
      "Training Results - Epoch: 76  Avg accuracy: 0.94 Avg loss: 1.59\n",
      "Validation Results - Epoch: 76  Avg accuracy: 0.88 Avg loss: 1.67\n",
      "Training Results - Epoch: 77  Avg accuracy: 0.94 Avg loss: 1.58\n",
      "Validation Results - Epoch: 77  Avg accuracy: 0.83 Avg loss: 1.67\n",
      "Training Results - Epoch: 78  Avg accuracy: 0.96 Avg loss: 1.58\n",
      "Validation Results - Epoch: 78  Avg accuracy: 0.88 Avg loss: 1.65\n",
      "Training Results - Epoch: 79  Avg accuracy: 0.94 Avg loss: 1.58\n",
      "Validation Results - Epoch: 79  Avg accuracy: 0.88 Avg loss: 1.67\n",
      "Training Results - Epoch: 80  Avg accuracy: 0.93 Avg loss: 1.59\n",
      "Validation Results - Epoch: 80  Avg accuracy: 0.86 Avg loss: 1.66\n",
      "Training Results - Epoch: 81  Avg accuracy: 0.95 Avg loss: 1.58\n",
      "Validation Results - Epoch: 81  Avg accuracy: 0.87 Avg loss: 1.67\n",
      "Training Results - Epoch: 82  Avg accuracy: 0.90 Avg loss: 1.61\n",
      "Validation Results - Epoch: 82  Avg accuracy: 0.83 Avg loss: 1.69\n",
      "Training Results - Epoch: 83  Avg accuracy: 0.89 Avg loss: 1.66\n",
      "Validation Results - Epoch: 83  Avg accuracy: 0.79 Avg loss: 1.76\n",
      "Training Results - Epoch: 84  Avg accuracy: 0.94 Avg loss: 1.58\n",
      "Validation Results - Epoch: 84  Avg accuracy: 0.88 Avg loss: 1.65\n",
      "Training Results - Epoch: 85  Avg accuracy: 0.94 Avg loss: 1.59\n",
      "Validation Results - Epoch: 85  Avg accuracy: 0.87 Avg loss: 1.65\n",
      "Training Results - Epoch: 86  Avg accuracy: 0.95 Avg loss: 1.58\n",
      "Validation Results - Epoch: 86  Avg accuracy: 0.88 Avg loss: 1.66\n",
      "Training Results - Epoch: 87  Avg accuracy: 0.93 Avg loss: 1.58\n",
      "Validation Results - Epoch: 87  Avg accuracy: 0.84 Avg loss: 1.68\n",
      "Training Results - Epoch: 88  Avg accuracy: 0.96 Avg loss: 1.58\n",
      "Validation Results - Epoch: 88  Avg accuracy: 0.86 Avg loss: 1.69\n",
      "Training Results - Epoch: 89  Avg accuracy: 0.94 Avg loss: 1.58\n",
      "Validation Results - Epoch: 89  Avg accuracy: 0.86 Avg loss: 1.67\n",
      "Training Results - Epoch: 90  Avg accuracy: 0.90 Avg loss: 1.60\n",
      "Validation Results - Epoch: 90  Avg accuracy: 0.84 Avg loss: 1.68\n",
      "Training Results - Epoch: 91  Avg accuracy: 0.95 Avg loss: 1.57\n",
      "Validation Results - Epoch: 91  Avg accuracy: 0.88 Avg loss: 1.65\n",
      "Training Results - Epoch: 92  Avg accuracy: 0.95 Avg loss: 1.57\n",
      "Validation Results - Epoch: 92  Avg accuracy: 0.85 Avg loss: 1.66\n",
      "Training Results - Epoch: 93  Avg accuracy: 0.95 Avg loss: 1.57\n",
      "Validation Results - Epoch: 93  Avg accuracy: 0.88 Avg loss: 1.65\n",
      "Training Results - Epoch: 94  Avg accuracy: 0.95 Avg loss: 1.58\n",
      "Validation Results - Epoch: 94  Avg accuracy: 0.88 Avg loss: 1.67\n",
      "Training Results - Epoch: 95  Avg accuracy: 0.83 Avg loss: 1.71\n",
      "Validation Results - Epoch: 95  Avg accuracy: 0.73 Avg loss: 1.81\n",
      "Training Results - Epoch: 96  Avg accuracy: 0.85 Avg loss: 1.61\n",
      "Validation Results - Epoch: 96  Avg accuracy: 0.76 Avg loss: 1.72\n",
      "Training Results - Epoch: 97  Avg accuracy: 0.94 Avg loss: 1.59\n",
      "Validation Results - Epoch: 97  Avg accuracy: 0.87 Avg loss: 1.68\n",
      "Training Results - Epoch: 98  Avg accuracy: 0.91 Avg loss: 1.62\n",
      "Validation Results - Epoch: 98  Avg accuracy: 0.78 Avg loss: 1.73\n",
      "Training Results - Epoch: 99  Avg accuracy: 0.95 Avg loss: 1.57\n",
      "Validation Results - Epoch: 99  Avg accuracy: 0.86 Avg loss: 1.67\n",
      "Training Results - Epoch: 100  Avg accuracy: 0.92 Avg loss: 1.59\n",
      "Validation Results - Epoch: 100  Avg accuracy: 0.81 Avg loss: 1.68\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.State at 0x7fe8a9f5dcf8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C =_C(input_h_w=64)\n",
    "C = C.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "C_optimizer = optim.Adam(C.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "log_interval = 10\n",
    "trainer = create_supervised_trainer(C, C_optimizer, F.cross_entropy, device='cuda')\n",
    "evaluator = create_supervised_evaluator(C, metrics={'accuracy': CategoricalAccuracy(),\n",
    "                                                     'ce_ll': Loss(F.cross_entropy)},\n",
    "                                           device='cuda')\n",
    "\n",
    "train_avg_loss_window = utils.create_plot_window(vis, '#Iterations', 'Loss', \n",
    "                                                 'Training Average Loss')\n",
    "train_avg_accuracy_window = utils.create_plot_window(vis, '#Iterations', 'Accuracy',\n",
    "                                                     'Training Average Accuracy')\n",
    "val_avg_loss_window = utils.create_plot_window(vis, '#Epochs', 'Loss',\n",
    "                                               'Validation Average Loss')\n",
    "val_avg_accuracy_window = utils.create_plot_window(vis, '#Epochs', 'Accuracy',\n",
    "                                                   'Validation Average Accuracy')\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    evaluator.run(train_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_nll = metrics['ce_ll']\n",
    "    print(\"Training Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(engine.state.epoch, avg_accuracy, avg_nll))\n",
    "    vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_accuracy]),\n",
    "             win=train_avg_accuracy_window, update='append')\n",
    "    vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_nll]),\n",
    "             win=train_avg_loss_window, update='append')\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    evaluator.run(val_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_nll = metrics['ce_ll']\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(engine.state.epoch, avg_accuracy, avg_nll))\n",
    "    vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_accuracy]),\n",
    "             win=val_avg_accuracy_window, update='append')\n",
    "    vis.line(X=np.array([engine.state.epoch]), Y=np.array([avg_nll]),\n",
    "             win=val_avg_loss_window, update='append')\n",
    "\n",
    "trainer.run(train_loader, max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<utils.utils.Subset at 0x7f5c10f2fda0>,\n",
       " <utils.utils.Subset at 0x7f5c10f2f240>,\n",
       " <utils.utils.Subset at 0x7f5c10f2fa20>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loader.dataset, train_loader.dataset, test_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,088\n",
      "         LeakyReLU-2           [-1, 64, 32, 32]               0\n",
      "            Conv2d-3          [-1, 128, 16, 16]         131,200\n",
      "       BatchNorm2d-4          [-1, 128, 16, 16]             256\n",
      "         LeakyReLU-5          [-1, 128, 16, 16]               0\n",
      "            Linear-6                 [-1, 1024]      33,555,456\n",
      "       BatchNorm1d-7                 [-1, 1024]           2,048\n",
      "         LeakyReLU-8                 [-1, 1024]               0\n",
      "            Linear-9                   [-1, 11]          11,275\n",
      "          Sigmoid-10                   [-1, 11]               0\n",
      "================================================================\n",
      "Total params: 33,701,323\n",
      "Trainable params: 33,701,323\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(C, (1, 64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix and classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.973 0.027 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.032 0.968 0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.125 0.    0.5   0.125 0.    0.    0.125 0.    0.125 0.   ]\n",
      " [0.    0.    0.    0.    0.846 0.    0.    0.    0.077 0.077 0.   ]\n",
      " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.1   0.9   0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.111 0.    0.    0.    0.778 0.111 0.   ]\n",
      " [0.    0.    0.    0.016 0.047 0.    0.    0.016 0.    0.922 0.   ]\n",
      " [0.    0.    0.    0.    0.333 0.    0.    0.    0.    0.    0.667]]\n",
      "[[ 5  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 73  2  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 30  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  4  1  0  0  1  0  1  0]\n",
      " [ 0  0  0  0 11  0  0  0  1  1  0]\n",
      " [ 0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  7  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  9  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  7  1  0]\n",
      " [ 0  0  0  1  3  0  0  1  0 59  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  2]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'window_365b604fcc212c'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchnet\n",
    "\n",
    "confusion_window = utils.create_plot_window(vis, 'True Labels', 'Predicted', 'Confusion Matrix')\n",
    "\n",
    "confusion_matrix = torchnet.meter.ConfusionMeter(11, normalized=True)\n",
    "for ii, data_ in enumerate(test_loader):\n",
    "    input_, label = data_\n",
    "    val_input = Variable(input_).cuda()\n",
    "    val_label = Variable(label.type(torch.LongTensor)).cuda()\n",
    "    score = C(val_input)\n",
    "    confusion_matrix.add(score.data.squeeze(), label.type(torch.LongTensor))\n",
    "    \n",
    "np.set_printoptions(precision=3)\n",
    "print(confusion_matrix.value())\n",
    "print(confusion_matrix.conf)\n",
    "vis.heatmap(confusion_matrix.value(), win=confusion_window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def iterations_test(C, test_loader):\n",
    "    y_real = list()\n",
    "    y_pred = list()\n",
    "\n",
    "    for ii, data_ in enumerate(test_loader):\n",
    "        input_, label = data_\n",
    "        val_input = Variable(input_).cuda()\n",
    "        val_label = Variable(label.type(torch.LongTensor)).cuda()\n",
    "        score = C(val_input)\n",
    "        _, y_pred_batch = torch.max(score, 1)\n",
    "        y_pred_batch = y_pred_batch.cpu().squeeze().numpy()\n",
    "        y_real_batch = val_label.cpu().data.squeeze().numpy()\n",
    "        y_real.append(y_real_batch.tolist())\n",
    "        y_pred.append(y_pred_batch.tolist())\n",
    "\n",
    "    y_real = [item for batch in y_real for item in batch]\n",
    "    y_pred = [item for batch in y_pred for item in batch]\n",
    "    \n",
    "    return y_real, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.80      1.00      0.89         4\n",
      "          1       0.95      0.97      0.96        73\n",
      "          2       0.97      0.91      0.94        33\n",
      "          3       0.38      0.75      0.50         4\n",
      "          4       0.92      0.63      0.75        19\n",
      "          5       0.50      0.50      0.50         2\n",
      "          6       1.00      0.88      0.93         8\n",
      "          7       0.80      0.89      0.84         9\n",
      "          8       0.67      0.86      0.75         7\n",
      "          9       0.92      0.89      0.91        66\n",
      "         10       0.67      1.00      0.80         2\n",
      "\n",
      "avg / total       0.91      0.89      0.90       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_real, y_pred = iterations_test(C, test_loader)\n",
    "print(metrics.classification_report(np.array(y_pred), np.array(y_real)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.905726872246696 [0.9162995594713657, 0.8986784140969163, 0.9074889867841409, 0.8942731277533039, 0.9118942731277533]\n"
     ]
    }
   ],
   "source": [
    "avg_acc = list()\n",
    "for i in range(5):\n",
    "    y_real, y_pred = iterations_test(C, test_loader)\n",
    "    avg_acc.append(metrics.accuracy_score(np.array(y_pred), np.array(y_real)))\n",
    "print(np.mean(avg_acc), avg_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
